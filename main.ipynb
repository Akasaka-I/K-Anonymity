{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Dataset:\n",
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n"
     ]
    }
   ],
   "source": [
    "# 下载成人数据集\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# 读取数据\n",
    "adult_data = pd.read_csv(url, names=column_names, header=None, na_values=\" ?\")\n",
    "adult_data.dropna(inplace=True)\n",
    "\n",
    "print(\"Adult Dataset:\")\n",
    "print(adult_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mondrian_k_anonymity(data, k):\n",
    "    def split_attribute(attribute, data):\n",
    "        unique_vals = data[attribute].unique()\n",
    "        if len(unique_vals) > 1:\n",
    "            median = np.median(data[attribute])\n",
    "            return data[data[attribute] <= median], data[data[attribute] > median]\n",
    "        return data, pd.DataFrame()\n",
    "\n",
    "    def partition(data, k):\n",
    "        if len(data) < 2 * k:\n",
    "            return [data]\n",
    "\n",
    "        best_attr = None\n",
    "        best_sets = None\n",
    "        max_size = 0\n",
    "\n",
    "        for attribute in data.columns:\n",
    "            if attribute == 'income':\n",
    "                continue\n",
    "            set1, set2 = split_attribute(attribute, data)\n",
    "            min_size = min(len(set1), len(set2))\n",
    "            if min_size >= k and min_size > max_size:\n",
    "                best_attr = attribute\n",
    "                best_sets = (set1, set2)\n",
    "                max_size = min_size\n",
    "\n",
    "        if best_attr is None:\n",
    "            return [data]\n",
    "\n",
    "        return partition(best_sets[0], k) + partition(best_sets[1], k)\n",
    "\n",
    "    partitions = partition(data, k)\n",
    "    anonymized_data = []\n",
    "\n",
    "    for partition in partitions:\n",
    "        for column in partition.columns:\n",
    "            if column == 'income':\n",
    "                continue\n",
    "            if partition[column].dtype == 'object':\n",
    "                most_common_value = partition[column].mode()[0]\n",
    "                partition[column] = most_common_value\n",
    "            else:\n",
    "                mean_value = partition[column].mean()\n",
    "                partition[column] = mean_value\n",
    "\n",
    "        anonymized_data.append(partition)\n",
    "\n",
    "    return pd.concat(anonymized_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行编码\n",
    "encoded_data = adult_data.copy()\n",
    "for column in encoded_data.columns:\n",
    "    if encoded_data[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        encoded_data[column] = le.fit_transform(encoded_data[column])\n",
    "\n",
    "# 对标签进行编码（-1和1）\n",
    "encoded_data['income'] = encoded_data['income'].apply(lambda x: 1 if x == 1 else -1)\n",
    "\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "encoded_data[encoded_data.columns[:-1]] = scaler.fit_transform(encoded_data[encoded_data.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized Adult Dataset:\n",
      "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
      "0 -1.241994   0.053125 -1.612375   0.043606       -0.63582        0.447176   \n",
      "1 -1.241994   0.053125 -1.612375   0.043606       -0.63582        0.447176   \n",
      "2 -1.241994   0.053125 -1.612375   0.043606       -0.63582        0.447176   \n",
      "3 -1.241994   0.053125 -1.612375   0.043606       -0.63582        0.447176   \n",
      "4 -1.241994   0.053125 -1.612375   0.043606       -0.63582        0.447176   \n",
      "\n",
      "   occupation  relationship     race       sex  capital-gain  capital-loss  \\\n",
      "0    0.196091        0.4413 -1.56177 -0.909352     -0.078229     -0.218586   \n",
      "1    0.196091        0.4413 -1.56177 -0.909352     -0.078229     -0.218586   \n",
      "2    0.196091        0.4413 -1.56177 -0.909352     -0.078229     -0.218586   \n",
      "3    0.196091        0.4413 -1.56177 -0.909352     -0.078229     -0.218586   \n",
      "4    0.196091        0.4413 -1.56177 -0.909352     -0.078229     -0.218586   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0       -0.547275        0.080657      -1  \n",
      "1       -0.547275        0.080657      -1  \n",
      "2       -0.547275        0.080657      -1  \n",
      "3       -0.547275        0.080657      -1  \n",
      "4       -0.547275        0.080657      -1  \n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "anonymized_data = mondrian_k_anonymity(encoded_data, k)\n",
    "\n",
    "print(\"Anonymized Adult Dataset:\")\n",
    "print(anonymized_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据分为训练集和测试集\n",
    "X_original = encoded_data.drop('income', axis=1)\n",
    "y_original = encoded_data['income']\n",
    "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(X_original, y_original, test_size=0.3, random_state=42)\n",
    "\n",
    "X_anonymized = anonymized_data.drop('income', axis=1)\n",
    "y_anonymized = anonymized_data['income']\n",
    "X_train_anonymized, X_test_anonymized, y_train_anonymized, y_test_anonymized = train_test_split(X_anonymized, y_anonymized, test_size=0.3, random_state=42)\n",
    "\n",
    "# 转换数据为PyTorch张量\n",
    "X_train_original = torch.tensor(X_train_original.values, dtype=torch.float32)\n",
    "y_train_original = torch.tensor(y_train_original.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_original = torch.tensor(X_test_original.values, dtype=torch.float32)\n",
    "y_test_original = torch.tensor(y_test_original.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train_anonymized = torch.tensor(X_train_anonymized.values, dtype=torch.float32)\n",
    "y_train_anonymized = torch.tensor(y_train_anonymized.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_anonymized = torch.tensor(X_test_anonymized.values, dtype=torch.float32)\n",
    "y_test_anonymized = torch.tensor(y_test_anonymized.values, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义SVM模型\n",
    "class SVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SVM, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "def hinge_loss(output, target):\n",
    "    return torch.mean(torch.clamp(1 - output * target, min=0))\n",
    "\n",
    "def train(model, X_train, y_train, epochs=100, lr=0.01):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = hinge_loss(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Original data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.8653\n",
      "Epoch [20/100], Loss: 0.6865\n",
      "Epoch [30/100], Loss: 0.5845\n",
      "Epoch [40/100], Loss: 0.5419\n",
      "Epoch [50/100], Loss: 0.5106\n",
      "Epoch [60/100], Loss: 0.4844\n",
      "Epoch [70/100], Loss: 0.4647\n",
      "Epoch [80/100], Loss: 0.4506\n",
      "Epoch [90/100], Loss: 0.4407\n",
      "Epoch [100/100], Loss: 0.4337\n"
     ]
    }
   ],
   "source": [
    "# 训练和测试原始数据上的SVM模型\n",
    "model_original = SVM(X_train_original.shape[1])\n",
    "train(model_original, X_train_original, y_train_original)\n",
    "\n",
    "model_original.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_original = model_original(X_test_original)\n",
    "    y_pred_original = torch.sign(y_pred_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training anonymized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.8872\n",
      "Epoch [20/100], Loss: 0.7807\n",
      "Epoch [30/100], Loss: 0.7160\n",
      "Epoch [40/100], Loss: 0.6814\n",
      "Epoch [50/100], Loss: 0.6534\n",
      "Epoch [60/100], Loss: 0.6262\n",
      "Epoch [70/100], Loss: 0.6001\n",
      "Epoch [80/100], Loss: 0.5764\n",
      "Epoch [90/100], Loss: 0.5553\n",
      "Epoch [100/100], Loss: 0.5376\n"
     ]
    }
   ],
   "source": [
    "# 训练和测试匿名化数据上的SVM模型\n",
    "model_anonymized = SVM(X_train_anonymized.shape[1])\n",
    "train(model_anonymized, X_train_anonymized, y_train_anonymized)\n",
    "\n",
    "model_anonymized.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_anonymized = model_anonymized(X_test_anonymized)\n",
    "    y_pred_anonymized = torch.sign(y_pred_anonymized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "           Original Data  Anonymized Data\n",
      "Accuracy        0.811913         0.747817\n",
      "Precision       0.764599         0.537500\n",
      "Recall          0.367222         0.074588\n",
      "AUC             0.664548         0.526320\n"
     ]
    }
   ],
   "source": [
    "# 计算评估指标\n",
    "y_pred_original_np = y_pred_original.numpy()\n",
    "y_test_original_np = y_test_original.numpy()\n",
    "\n",
    "y_pred_anonymized_np = y_pred_anonymized.numpy()\n",
    "y_test_anonymized_np = y_test_anonymized.numpy()\n",
    "\n",
    "results = {\n",
    "    'Original Data': {\n",
    "        'Accuracy': accuracy_score(y_test_original_np, y_pred_original_np),\n",
    "        'Precision': precision_score(y_test_original_np, y_pred_original_np),\n",
    "        'Recall': recall_score(y_test_original_np, y_pred_original_np),\n",
    "        'AUC': roc_auc_score(y_test_original_np, y_pred_original_np)\n",
    "    },\n",
    "    'Anonymized Data': {\n",
    "        'Accuracy': accuracy_score(y_test_anonymized_np, y_pred_anonymized_np),\n",
    "        'Precision': precision_score(y_test_anonymized_np, y_pred_anonymized_np),\n",
    "        'Recall': recall_score(y_test_anonymized_np, y_pred_anonymized_np),\n",
    "        'AUC': roc_auc_score(y_test_anonymized_np, y_pred_anonymized_np)\n",
    "    }\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Evaluation Results:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
